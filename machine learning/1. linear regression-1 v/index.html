
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.8">
    
    
      
        <title>一. 单变量线性回归 - 大白的知识库</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.644de097.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.e6a45f82.min.css">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="大白的知识库" class="md-header__button md-logo" aria-label="大白的知识库" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            大白的知识库
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              一. 单变量线性回归
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../.." class="md-tabs__link">
      首页
    </a>
  </li>

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../" class="md-tabs__link md-tabs__link--active">
        机器学习
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="大白的知识库" class="md-nav__button md-logo" aria-label="大白的知识库" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    大白的知识库
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        首页
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          机器学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="机器学习" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          机器学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        前言和目录
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          一. 单变量线性回归
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        一. 单变量线性回归
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    1. 模型描述
  </a>
  
    <nav class="md-nav" aria-label="1. 模型描述">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    1.1 举例引入
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    1.2 模型描述
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    2. 代价函数
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-1" class="md-nav__link">
    3 代价函数直观理解1
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-ii" class="md-nav__link">
    4. 代价函数的直观理解II
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    5. 梯度下降
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../2.%20linear%20regression-m%20v/" class="md-nav__link">
        二. 多变量线性回归
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    1. 模型描述
  </a>
  
    <nav class="md-nav" aria-label="1. 模型描述">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    1.1 举例引入
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    1.2 模型描述
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    2. 代价函数
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-1" class="md-nav__link">
    3 代价函数直观理解1
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-ii" class="md-nav__link">
    4. 代价函数的直观理解II
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    5. 梯度下降
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


  <h1>一. 单变量线性回归</h1>

<h2 id="1">1. 模型描述</h2>
<div class="admonition info">
<p>参考视频:
2 - 1 - Model Representation (8 min).mkv</p>
</div>
<h3 id="11">1.1 举例引入</h3>
<p>我们这里有一个俄勒冈州波特兰市的<strong>住房价格数据集</strong>，数据集包含：房屋<strong>尺寸</strong>，房屋<strong>出售价格</strong>......然后，你有一个朋友。他有一套1250平的房子，他需要你告诉他这房子能卖多少钱。我们该怎么做？</p>
<h3 id="12">1.2 模型描述</h3>
<p>1.1 中的部分数据集如下表所示：</p>
<table>
<thead>
<tr>
<th>Size   in <span class="arithmatex">\(feet^2 (x)\)</span></th>
<th>Price ($) in <span class="arithmatex">\(1000's (y)\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td>2104</td>
<td>460</td>
</tr>
<tr>
<td>1416</td>
<td>232</td>
</tr>
<tr>
<td>1534</td>
<td>315</td>
</tr>
<tr>
<td>852</td>
<td>178</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<p>上述数据集，我们通常称为<strong>训练集</strong>（<strong>training set</strong>）。</p>
<p>为了<strong>方便描述</strong>和后面<strong>公式推导</strong>将这个问题进行如下<strong>标记（Notion）</strong>：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(m\)</span></td>
<td><strong>样本数量（number of training examples ）</strong></td>
</tr>
<tr>
<td><span class="arithmatex">\(x\)</span></td>
<td><strong>输入变量/特征（input of variable/features）</strong></td>
</tr>
<tr>
<td><span class="arithmatex">\(y\)</span></td>
<td><strong>目标变量/输出变量（output variable / target variable）</strong></td>
</tr>
<tr>
<td><span class="arithmatex">\((x, y)\)</span></td>
<td><strong>一个样本（one training example）</strong></td>
</tr>
<tr>
<td><span class="arithmatex">\((x^{(i)}, y^{(i)})\)</span></td>
<td><strong>第<span class="arithmatex">\(i\)</span>个样本</strong></td>
</tr>
</tbody>
</table>
<p>好了，下面先来<strong>明确一下</strong>我们<strong>已知条件</strong>和<strong>要做的事</strong>：</p>
<p>我们已知了训练集（m组数据：<span class="arithmatex">\((x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), ...(x^{(m)}, y^{(m)}), 其中(x^{(i)}, y^{(i)})\)</span>代表了第 i 组的（房屋尺寸，房屋价格）），根据这个训练集，我们要训练出我们的模型（函数），通常表示为h，即<strong>hypothesis(假设)</strong>。而这个函数h的输入是房屋尺寸，输出就是房屋价格。因此，h 是一个从x 到 y 的函数映射。</p>
<p><img alt="1_1_1_training_flow" src="../../assets/images/1_1_1_training_flow.png" /></p>
<p>那么，对于我们这个问题，我们应该如何描述<span class="arithmatex">\(h\)</span>？</p>
<p>一种可能的表达方式为：
$$
h_\theta \left( x \right)=\theta_{0} + \theta_{1}x\tag{1.2.1}
$$
因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>线性回归中<ins class="critic">线性</ins>的含义： 因变量<ins class="critic">y</ins>对于<ins class="critic">未知的回归系数</ins>（<span class="arithmatex">\(\theta_0\)</span>，<span class="arithmatex">\(\theta_1\)</span>，.... <span class="arithmatex">\(\theta_n\)</span>） 是<ins class="critic">线性</ins>的。</p>
</div>
<h2 id="2">2. 代价函数</h2>
<div class="admonition info">
<p>参考视频:
2 - 2 - Cost Function (8 min).mkv</p>
</div>
<p>Training Set</p>
<table>
<thead>
<tr>
<th>Size   in <span class="arithmatex">\(feet^2 (x)\)</span></th>
<th>Price ($) in <span class="arithmatex">\(1000's (y)\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td>2104</td>
<td>460</td>
</tr>
<tr>
<td>1416</td>
<td>232</td>
</tr>
<tr>
<td>1534</td>
<td>315</td>
</tr>
<tr>
<td>852</td>
<td>178</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<p>Hypothesis:    <span class="arithmatex">\(h_\theta \left( x \right)=\theta_{0}+\theta_{1}x\)</span></p>
<p>Parameters: <span class="arithmatex">\(\theta_{0}\)</span> ， <span class="arithmatex">\(\theta_{1}\)</span></p>
<p>通过上一节，我们知道了，我们要完成朋友的<strong>需求（根据他房子的大小预测房价</strong>），要知道假设函数    <span class="arithmatex">\(h\)</span>，我们对    <span class="arithmatex">\(h\)</span>     做出这样一种假设：<span class="arithmatex">\(h_\theta \left( x \right)=\theta_{0}+\theta_{1}x\)</span>。通过观察这个函数，我们可以把这个问题转化为求<span class="arithmatex">\(\theta_{0}\)</span> 和 <span class="arithmatex">\(\theta_{1}\)</span>，从而当你朋友把房子大小告诉你，你将其代入公式即可得到预测的房价。那么，我们如何选择呢<span class="arithmatex">\(\theta_{0}\)</span> 和 <span class="arithmatex">\(\theta_{1}\)</span>？</p>
<p>首先，我们先直观理解<span class="arithmatex">\(h_\theta \left( x \right)\)</span> ---下图是<span class="arithmatex">\(\theta_{0}\)</span> 和 <span class="arithmatex">\(\theta_{1}\)</span>取不同值时，<span class="arithmatex">\(h\)</span>的整体图像。</p>
<p><img alt="1_2_1_figure_of_h" src="../../assets/images/1_2_1_figure_of_h.png" /></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>上面图像为了方便省略了<span class="arithmatex">\(\theta\)</span>下标，即 <span class="arithmatex">\(h_\theta(x) = h(x)\)</span>，后面也可能会这样做。</p>
</div>
<p><strong>结合图像描述我们的任务</strong></p>
<ul>
<li>把训练集数据绘制在下图中（并非上面的房价训练集，仅举例示意）</li>
</ul>
<p><img alt="1_2_2_datasets_in_figrue" src="../../assets/images/1_2_2_datasets_in_figrue.png" /></p>
<ul>
<li>我们要做的就是绘制一条直线（下图蓝色的线）尽量地与上面那些点有和好的拟合，这条直线就是<span class="arithmatex">\(h_\theta(x)\)</span>。如何确定这条直线也就是确定<span class="arithmatex">\(\theta_0\)</span>和<span class="arithmatex">\(\theta_1\)</span>。</li>
</ul>
<p><img alt="1_2_3_line_fit" src="../../assets/images/1_2_3_line_fit.png" /></p>
<ul>
<li>我们的idea：</li>
</ul>
<p>Choose <span class="arithmatex">\(\theta_0, \theta_1\)</span></p>
<p>so that <span class="arithmatex">\(h_\theta(x)\)</span>  is close to  <span class="arithmatex">\(y\)</span>  for our training examples  <span class="arithmatex">\((x, y)\)</span></p>
<p>将我们的任务以公式化标记，即：</p>
<div class="arithmatex">\[
\mathop{minimize} \limits_{\theta_0,\ \theta_1}\   \frac {1} {2m}\cdot\sum\limits_{i=1}^{m}\Big(h_\theta(x^{(i)})-y^{(i)}\Big)^2 \tag{2.1.1}
\]</div>
<p>线性回归实际上就是解决一个关于<span class="arithmatex">\(\theta_0, \theta_1\)</span>的最小化问题(minimize)。我们希望我们的直线与那些点有很好的拟合，那我们把每一个点预测得到的值<span class="arithmatex">\(\Big(\)</span>将x代入假设函数可得到，即<span class="arithmatex">\(h_\theta(x)\Big)\)</span>与真实值y求一个差的平方。再把这些平方累加。即:</p>
<div class="arithmatex">\[
\sum\limits_{i=1}^{m}\Big(h_\theta(x^{(i)})-y^{(i)}\Big)^2 \tag{2.1.2}
\]</div>
<p>我们只要让这个平方和最小即可。</p>
<p>注意, </p>
<p>关于式(2.1.1)前面<span class="arithmatex">\(\frac{1}{2m}\)</span></p>
<ul>
<li><span class="arithmatex">\(\frac{1}{m}\)</span>是因为求和项有m个，这里除以m，是求平均值。</li>
<li><span class="arithmatex">\(\frac{1}{2}\)</span>为了后面求导消去</li>
<li>其实这个<span class="arithmatex">\(\frac{1}{2m}\)</span>对我们求最小值没有任何影响，只是为了计算方便这么写。</li>
</ul>
<p>关于式(2.1.2)的几何意义</p>
<ul>
<li>所有数据点与拟合直线在y轴方向的截距的平方和</li>
</ul>
<p>在本例子中，</p>
<ul>
<li><span class="arithmatex">\(h_\theta \left( x \right)=\theta_{0} + \theta_{1}x\)</span></li>
</ul>
<p>通常，为了方便起见，我们定义一个函数，也就是代价函数(cost function)，如下：</p>
<div class="arithmatex">\[
J(\theta_0,\theta_1)=\frac {1} {2m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2\tag{2.1.3}
\]</div>
<p>我们的最终目标就转化为：</p>
<div class="arithmatex">\[
\mathop{minimize} \limits_{\theta_0,\ \theta_1}J(\theta_0,\theta_1)
\]</div>
<p>这里我们定义的式(2.1.3)损失函数, 也被称为平方误差函数(squared error function)。然而，损失函数不止这一种形式，但是在回归问题中，平方误差函数都是比较合理和比较常用的选择。</p>
<h2 id="3-1">3 代价函数直观理解1</h2>
<div class="admonition info">
<p>参考视频:
2 - 3 - Cost Function - Intuition I (11 min).mkv</p>
</div>
<p>在上一个小节，我们得到了代价函数的定义。在这一小节中，我们通过一个例子来获取一些直观的感受，看看代价函数到底是在干什么。</p>
<p>Hypothesis: <span class="arithmatex">\(h_\theta(x)=\theta_0+\theta_1x\)</span></p>
<p>Parameters: <span class="arithmatex">\(\theta_0,\ \theta_1\)</span></p>
<p>Cost Function: <span class="arithmatex">\(J(\theta_0,\theta_1)=\frac {1} {2m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2\)</span></p>
<p>Goal: <span class="arithmatex">\(\mathop{minimize} \limits_{\theta_0,\ \theta_1}J(\theta_0,\theta_1)\)</span></p>
<p>为了让代价函数 <span class="arithmatex">\(J\)</span> 有更好的，可视化效果，我们简化假设函数为<span class="arithmatex">\(h_\theta(x)=\theta_1x\)</span>，即假设<span class="arithmatex">\(\theta_0=0\)</span>。简化后：</p>
<p><span class="arithmatex">\(h_\theta(x)=\theta_1x\)</span></p>
<p><span class="arithmatex">\(J(\theta_1)=\frac {1} {2m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2\)</span></p>
<p>Goal: <span class="arithmatex">\(\mathop{minimize} \limits_{\theta_1}J(\theta_1)\)</span></p>
<p>在确定好不同的 <span class="arithmatex">\(\theta_1\)</span> ,之后画出假设函数 <span class="arithmatex">\(h\)</span> 和代价函数 <span class="arithmatex">\(J\)</span>。本例中，假定训练集为<span class="arithmatex">\((1,1), (2,2), (3,3)\)</span>。</p>
<ul>
<li>当 <span class="arithmatex">\(\theta_1=1\)</span> 时，</li>
</ul>
<p><img alt="1_3_1_h&amp;J_theta1=1" src="../../assets/images/1_3_1_h%26J_theta1%3D1.png" /></p>
<p>注意到，因为<span class="arithmatex">\(\theta_1=1\)</span>，此时 <span class="arithmatex">\(h_\theta=y\)</span> ,所以 <span class="arithmatex">\(J=0\)</span> 。并在右边图上画出第一个点(1,0)。</p>
<ul>
<li>当 <span class="arithmatex">\(\theta_1=0.5\)</span> 时，</li>
</ul>
<p><img alt="1_3_2_h&amp;J_theta=0.5" src="../../assets/images/1_3_2_h%26J_theta%3D0.5.png" /></p>
<p><span class="arithmatex">\((x,y)\)</span>依次取(1, 0.5), (2, 1), (3, 1.5) 计算 <span class="arithmatex">\(J \approx 0.58\)</span> 。并在右边图上画出第二个点(0.5,0.58)。</p>
<ul>
<li>当 <span class="arithmatex">\(\theta_1=0\)</span> 时，</li>
</ul>
<p><img alt="1_3_3_h&amp;J_theta=0" src="../../assets/images/1_3_3_h%26J_theta%3D0.png" /></p>
<p>同理，当 <span class="arithmatex">\(\theta_1\)</span> 取不同值时，我们可以计算出 <span class="arithmatex">\(J\)</span> ，并在右侧画出 <span class="arithmatex">\(J\)</span> 的大致图像。</p>
<p><img alt="1_3_4_h&amp;J_all_theta" src="../../assets/images/1_3_4_h%26J_all_theta.png" /></p>
<p>总结：
我们通过取不同的 <span class="arithmatex">\(\theta_1\)</span> ，绘制出了 <span class="arithmatex">\(J\)</span> 。</p>
<p><img alt="1_3_5_h&amp;J_all_theta" src="../../assets/images/1_3_5_h%26J_dif_theta.png" /></p>
<p>So for each value of <span class="arithmatex">\(\theta_1\)</span> , we wound up with a diffent value of <span class="arithmatex">\(J(\theta_1)\)</span> . And we colud then use this to trace out this plot on the right. 
Now you remember the optimization objective for our learning algorithm is we want to choose the value of <span class="arithmatex">\(\theta_1\)</span> that minimize <span class="arithmatex">\(J(\theta_1)\)</span>. This was our objective function for the linear regression. </p>
<p>现在，我们观察右侧那条曲线，会发现，当 <span class="arithmatex">\(\theta_1=1\)</span> 时，<span class="arithmatex">\(J(\theta_1)\)</span>最小。再观察左边的拟合情况会发现，这确实是最好的情况。对于这个特殊的训练集，我们确实完美地拟合了它。</p>
<p>And that's why minimizing <span class="arithmatex">\(J(\theta_1)\)</span> corresponds to finding a straight line that fits the data well. </p>
<h2 id="4-ii">4. 代价函数的直观理解II</h2>
<div class="admonition info">
<p>参考视频:
2 - 4 - Cost Function - Intuition II (9 min).mkv</p>
</div>
<p><img alt="1_4_1_J_3D" src="../../assets/images/1_4_1_J_3D.png" /></p>
<p>代价函数的样子，则可以看出在三维空间中存在一个使得<span class="arithmatex">\(J(\theta_{0}, \theta_{1})\)</span>最小的点。</p>
<p><img alt="1_4_2_h&amp;Jdenggaoxian" src="../../assets/images/1_4_2_h%26Jdenggaoxian.png" /></p>
<p>通过这些图形，我希望你能更好地理解这些代价函数 <span class="arithmatex">\(J\)</span> 所表达的值是什么样的，它们对应的假设函数是什么样的，以及什么样的假设对应的点，更接近于代价函数 <span class="arithmatex">\(J\)</span> 的最小值。</p>
<p>当然，我们真正需要的是一种有效的算法，能够自动地找出这些使代价函数 <span class="arithmatex">\(J\)</span> 取最小值的参数 <span class="arithmatex">\(\theta_{0}\)</span> 和 <span class="arithmatex">\(\theta_{1}\)</span> 来。</p>
<p>我们也不希望编个程序把这些点画出来，然后人工的方法来读出这些点的数值，这很明显不是一个好办法。我们会遇到更复杂、更高维度、更多参数的情况，而这些情况是很难画出图的，因此更无法将其可视化，因此我们真正需要的是编写程序来找出这些最小化代价函数的 <span class="arithmatex">\(\theta_{0}\)</span> 和 <span class="arithmatex">\(\theta_{1}\)</span> 的值，在下一节视频中，我们将介绍一种算法，能够自动地找出能使代价函数 <span class="arithmatex">\(J\)</span> 最小化的参数 <span class="arithmatex">\(\theta_{0}\)</span> 和 <span class="arithmatex">\(\theta_{1}\)</span> 的值。</p>
<h2 id="5">5. 梯度下降</h2>
<div class="admonition info">
<p>参考视频:
2 - 5 - Gradient Descent (11 min).mkv</p>
</div>
<p>梯度下降是一个用来求函数最小值的算法，我们将使用梯度下降算法来求出代价函数<span class="arithmatex">\(J(\theta_{0}, \theta_{1})\)</span> 的最小值。</p>
<p>梯度下降背后的思想是：开始时我们随机选择一个参数的组合<span class="arithmatex">\(\left( {\theta_{0}},{\theta_{1}},......,{\theta_{n}} \right)\)</span>，计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。我们持续这么做直到找到一个局部最小值（<strong>local minimum</strong>），因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（<strong>global minimum</strong>），选择不同的初始参数组合，可能会找到不同的局部最小值。</p>
<p><img alt="1_5_1_J_dif_start" src="../../assets/images/1_5_1_J_dif_start.png" /></p>
<p>想象一下你正站立在山的这一点上，站立在你想象的公园这座红色山上，在梯度下降算法中，我们要做的就是旋转360度，看看我们的周围，并问自己要在某个方向上，用小碎步尽快下山。这些小碎步需要朝什么方向？如果我们站在山坡上的这一点，你看一下周围，你会发现最佳的下山方向，你再看看周围，然后再一次想想，我应该从什么方向迈着小碎步下山？然后你按照自己的判断又迈出一步，重复上面的步骤，从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。</p>
<p>批量梯度下降（<strong>batch gradient descent</strong>）算法的公式为：</p>
<div class="arithmatex">\[
repeat until convergence {\\\\
\theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta_0, \theta_1)\\\\
\\\\}
\]</div>
<p>其中 <span class="arithmatex">\(\alpha\)</span> 是学习率（<strong>learning rate</strong>），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数。</p>
<p>在梯度下降算法中，还有一个更微妙的问题，梯度下降中，我们要更新<span class="arithmatex">\({\theta_{0}}\)</span>和<span class="arithmatex">\({\theta_{1}}\)</span> ，当 <span class="arithmatex">\(j=0\)</span> 和<span class="arithmatex">\(j=1\)</span>时，会产生更新，所以你将更新<span class="arithmatex">\(J\left( {\theta_{0}} \right)\)</span>和<span class="arithmatex">\(J\left( {\theta_{1}} \right)\)</span>。实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要同时更新<span class="arithmatex">\({\theta_{0}}\)</span>和<span class="arithmatex">\({\theta_{1}}\)</span>，我的意思是在这个等式中，我们要这样更新：<span class="arithmatex">\({\theta_{0}}\)</span>:= <span class="arithmatex">\({\theta_{0}}\)</span> ，并更新<span class="arithmatex">\({\theta_{1}}\)</span>:= <span class="arithmatex">\({\theta_{1}}\)</span>。</p>
<p>实现方法是：你应该计算公式右边的部分，通过那一部分计算出<span class="arithmatex">\({\theta_{0}}\)</span>和<span class="arithmatex">\({\theta_{1}}\)</span>的值，然后同时更新<span class="arithmatex">\({\theta_{0}}\)</span>和<span class="arithmatex">\({\theta_{1}}\)</span>。</p>
<p>让我进一步阐述这个过程：</p>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            回到页面顶部
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="页脚">
      
        
        <a href="../" class="md-footer__link md-footer__link--prev" aria-label="上一页: 前言和目录" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                上一页
              </span>
              前言和目录
            </div>
          </div>
        </a>
      
      
        
        <a href="../2.%20linear%20regression-m%20v/" class="md-footer__link md-footer__link--next" aria-label="下一页: 二. 多变量线性回归" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                下一页
              </span>
              二. 多变量线性回归
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.top"], "search": "../../assets/javascripts/workers/search.5e67fbfe.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version.title": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c44cc438.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>